---
layout: default
title: Yu-Gi-Oh! Life Counter with AfterAI Flaps
---

<style>
    .callout {
        padding: 20px;
        margin: 20px 0;
        border-left: 5px solid;
        border-radius: 5px;
    }
    .callout-note {
        background-color: #f0f7fb;
        border-left-color: #007bff;
    }
    .callout-question {
        background-color: #fdf7e4;
        border-left-color: #ffc107;
    }
    .callout-success {
        background-color: #eaf7ea;
        border-left-color: #28a745;
    }
    .img-fluid {
        max-width: 100%;
        height: auto;
    }
    .video-container {
        position: relative;
        padding-bottom: 56.25%;
        height: 0;
        overflow: hidden;
        max-width: 100%;
        background: #000;
    }
    .video-container iframe {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }
    .content ul {
        font-size: 1.1rem;
        margin-left: 30px;
        margin-bottom: 20px;
    }
    .content table {
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
    }
    .content th, .content td {
        border: 1px solid var(--pencil-gray);
        padding: 8px;
        text-align: left;
    }
    .content th {
        background-color: #f2f2f2;
    }
    .content img {
        max-width: 600px;
        display: block;
        margin: 0;
    }
</style>

<div class="content">
    <h1>Yu-Gi-Oh! Life Counter with AfterAI Flaps</h1>
    <p>When I was a kid, keeping track of Life Points (LP) in Yu-Gi-Oh! was always a hassle. This time, I decided to use <a href="/works/flaps.html">AfterAI Flaps</a> to calculate and display the Life Points for the game.</p>

    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/Sd2KLeK7nvY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>

    <p>GitHub: <a href="https://github.com/AfterAILab/Yu_Gi_Oh_Life_Counter" target="_blank" rel="noopener noreferrer">https://github.com/AfterAILab/Yu_Gi_Oh_Life_Counter</a></p>

    <h2>Deployment Diagram</h2>
    <p><img src="/img/yugioh/YGODeploymentDiagram.png" alt="Yu-Gi-Oh! Life Counter Deployment Diagram" class="img-fluid"></p>
    <p><strong>Tools Used:</strong></p>
    <ul>
        <li><strong>AfterAI Flaps (5 characters):</strong> Displays whose turn it is.</li>
        <li><strong>AfterAI Flaps (9 characters):</strong> Displays the Life Points for both players.</li>
        <li><strong>MacBook Pro (M2):</strong> My trusty MacBook for running everything smoothly.</li>
    </ul>

    <h2>Computer Setup</h2>
    <p>Since the MacBook Pro (M2) has plenty of computing power, I decided to run all the calculations locally. For Speech-to-Text, I used <a href="https://alphacephei.com/vosk" target="_blank" rel="noopener noreferrer">Vosk</a>, and to extract commands from text, I initially tried using llama3.2 through <a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">Ollama</a>. <em>However, llama3.2 (3B) often returned incorrect results, so I ended up switching to OpenAI's gpt-4o-mini.</em></p>

    <h2>Flow Chart</h2>
    <p><img src="/img/yugioh/YGOFlowChart.png" alt="Yu-Gi-Oh! Life Counter Flow Chart" class="img-fluid"></p>
    <p>Whenever a phrase like "Inflict XXX damage to opponent" is spoken, the system retrieves the opponent's current Life Points via a GET request from the display. After calculating the damage, it updates the displayed number using a POST request.</p>
    <p>For simplicity’s sake, I didn’t include the "My turn, draw!" process in the flowchart, but it follows a similar logic. You can check out the code for more details.</p>

    <h3>Prompting Issues</h3>
    <p>I initially tried having llama3.2 (3B) handle this task:</p>
    <blockquote>
        <p><strong>Input:</strong> Current turn and transcribed speech data.</p>
        <p><strong>Output:</strong> Game state changes (damage, healing, next turn, etc.).</p>
    </blockquote>
    <p>However, llama3.2 struggled with this and often ended up healing the opponent instead of inflicting damage. I tried improving the prompt with help from other AIs, but it still didn’t work as expected. In the end, I fed the same prompt to OpenAI's gpt-4o-mini, and it worked perfectly.</p>

    <h2>Conclusion</h2>
    <ul>
        <li><strong>AfterAI Flaps</strong> can be effectively used as part of a DIY project.
            <ul>
                <li>Consider upgrading to version 1.2 if needed.</li>
            </ul>
        </li>
        <li><strong>Improving real-time performance:</strong> It might help to interrupt mid-speech rather than waiting for speech completion events from the voice engine.
            <ul>
                <li>If you can adjust the delay before these events occur via engine parameters, that would be ideal.</li>
            </ul>
        </li>
        <li><strong>Model performance varies significantly:</strong> Even for small tasks like this one.
            <ul>
                <li>While llama is a well-known model, its struggle with this task was unexpected.</li>
                <li>There are versions of llama3.2 with more parameters than 3B; perhaps those would perform better.</li>
                <li>I couldn’t find any information on the exact number of parameters for gpt-4o-mini after searching online.</li>
            </ul>
        </li>
    </ul>
</div>
